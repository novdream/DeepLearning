{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, datasets\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}\n",
    "\n",
    "def mnist_dataset():\n",
    "    (x, y), (x_test, y_test) = datasets.mnist.load_data()\n",
    "    #normalize\n",
    "    x = x/255.0\n",
    "    x_test = x_test/255.0\n",
    "    \n",
    "    return (x, y), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip([1, 2, 3, 4], ['a', 'b', 'c', 'd'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myModel:\n",
    "    def __init__(self):\n",
    "        ####################\n",
    "        '''声明模型对应的参数'''\n",
    "        ####################\n",
    "        self.W1 = tf.Variable(initial_value=tf.random.normal(shape=[28*28,100],dtype=tf.float32))\n",
    "        self.W2 = tf.Variable(initial_value=tf.random.normal(shape=[100,10],dtype=tf.float32))\n",
    "        self.b1 = tf.Variable(initial_value=tf.zeros(shape=[100],dtype=tf.float32))\n",
    "        self.b2 = tf.Variable(initial_value=tf.zeros(shape=[10],dtype=tf.float32))\n",
    "    def __call__(self, x):\n",
    "        ####################\n",
    "        '''实现模型函数体，返回未归一化的logits'''\n",
    "        ####################\n",
    "        x_new = tf.reshape(x,[-1,28*28])#展平成二维\n",
    "        hidden = tf.nn.relu(tf.matmul(x_new,self.W1)+self.b1)\n",
    "        logits = tf.matmul(hidden,self.W2)+self.b2\n",
    "        return logits\n",
    "        \n",
    "model = myModel()\n",
    "\n",
    "optimizer = optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_loss(logits, labels):\n",
    "    return tf.reduce_mean(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=labels))\n",
    "\n",
    "@tf.function\n",
    "def compute_accuracy(logits, labels):\n",
    "    predictions = tf.argmax(logits, axis=1)\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(predictions, labels), tf.float32))\n",
    "\n",
    "@tf.function\n",
    "def train_one_step(model, optimizer, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x)\n",
    "        loss = compute_loss(logits, y)\n",
    "\n",
    "    # compute gradient\n",
    "    trainable_vars = [model.W1, model.W2, model.b1, model.b2]\n",
    "    grads = tape.gradient(loss, trainable_vars)\n",
    "    for g, v in zip(grads, trainable_vars):\n",
    "        v.assign_sub(0.05*g)\n",
    "\n",
    "    accuracy = compute_accuracy(logits, y)\n",
    "\n",
    "    # loss and accuracy is scalar tensor\n",
    "    return loss, accuracy\n",
    "\n",
    "@tf.function\n",
    "def test(model, x, y):\n",
    "    logits = model(x)\n",
    "    loss = compute_loss(logits, y)\n",
    "    accuracy = compute_accuracy(logits, y)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实际训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : loss 105.43903 ; accuracy 0.0931\n",
      "epoch 1 : loss 70.10627 ; accuracy 0.10208333\n",
      "epoch 2 : loss 59.168552 ; accuracy 0.124066666\n",
      "epoch 3 : loss 52.162067 ; accuracy 0.14836666\n",
      "epoch 4 : loss 46.495224 ; accuracy 0.16938333\n",
      "epoch 5 : loss 41.667667 ; accuracy 0.19071667\n",
      "epoch 6 : loss 37.639324 ; accuracy 0.2117\n",
      "epoch 7 : loss 34.40866 ; accuracy 0.23398334\n",
      "epoch 8 : loss 31.806759 ; accuracy 0.25678334\n",
      "epoch 9 : loss 29.608688 ; accuracy 0.27785\n",
      "epoch 10 : loss 27.673944 ; accuracy 0.29715\n",
      "epoch 11 : loss 25.955088 ; accuracy 0.31753334\n",
      "epoch 12 : loss 24.43153 ; accuracy 0.33601665\n",
      "epoch 13 : loss 23.075996 ; accuracy 0.35325\n",
      "epoch 14 : loss 21.867767 ; accuracy 0.37115\n",
      "epoch 15 : loss 20.79315 ; accuracy 0.38788334\n",
      "epoch 16 : loss 19.83434 ; accuracy 0.40313333\n",
      "epoch 17 : loss 18.97701 ; accuracy 0.4181\n",
      "epoch 18 : loss 18.207842 ; accuracy 0.43218333\n",
      "epoch 19 : loss 17.513494 ; accuracy 0.44516668\n",
      "epoch 20 : loss 16.885286 ; accuracy 0.45756668\n",
      "epoch 21 : loss 16.313917 ; accuracy 0.469\n",
      "epoch 22 : loss 15.792785 ; accuracy 0.48035\n",
      "epoch 23 : loss 15.315465 ; accuracy 0.49083334\n",
      "epoch 24 : loss 14.876027 ; accuracy 0.50016665\n",
      "epoch 25 : loss 14.470158 ; accuracy 0.51018333\n",
      "epoch 26 : loss 14.094284 ; accuracy 0.51851666\n",
      "epoch 27 : loss 13.744198 ; accuracy 0.5262\n",
      "epoch 28 : loss 13.416919 ; accuracy 0.5334\n",
      "epoch 29 : loss 13.110025 ; accuracy 0.54035\n",
      "epoch 30 : loss 12.821493 ; accuracy 0.5472\n",
      "epoch 31 : loss 12.549569 ; accuracy 0.55336666\n",
      "epoch 32 : loss 12.292841 ; accuracy 0.55975\n",
      "epoch 33 : loss 12.050039 ; accuracy 0.56626666\n",
      "epoch 34 : loss 11.819969 ; accuracy 0.57145\n",
      "epoch 35 : loss 11.601536 ; accuracy 0.57703334\n",
      "epoch 36 : loss 11.393897 ; accuracy 0.58248335\n",
      "epoch 37 : loss 11.196245 ; accuracy 0.58751667\n",
      "epoch 38 : loss 11.0077915 ; accuracy 0.59265\n",
      "epoch 39 : loss 10.828033 ; accuracy 0.5973833\n",
      "epoch 40 : loss 10.656304 ; accuracy 0.602\n",
      "epoch 41 : loss 10.491987 ; accuracy 0.60655\n",
      "epoch 42 : loss 10.334571 ; accuracy 0.6103\n",
      "epoch 43 : loss 10.183614 ; accuracy 0.6141833\n",
      "epoch 44 : loss 10.038659 ; accuracy 0.61793333\n",
      "epoch 45 : loss 9.89926 ; accuracy 0.6214667\n",
      "epoch 46 : loss 9.765115 ; accuracy 0.6247333\n",
      "epoch 47 : loss 9.63591 ; accuracy 0.6279333\n",
      "epoch 48 : loss 9.511326 ; accuracy 0.6317833\n",
      "epoch 49 : loss 9.391065 ; accuracy 0.6347167\n",
      "epoch 50 : loss 9.274983 ; accuracy 0.6383167\n",
      "epoch 51 : loss 9.16285 ; accuracy 0.64108336\n",
      "epoch 52 : loss 9.0544405 ; accuracy 0.64388335\n",
      "epoch 53 : loss 8.94956 ; accuracy 0.64668334\n",
      "epoch 54 : loss 8.84805 ; accuracy 0.64935\n",
      "epoch 55 : loss 8.749747 ; accuracy 0.65216666\n",
      "epoch 56 : loss 8.654525 ; accuracy 0.65501666\n",
      "epoch 57 : loss 8.562254 ; accuracy 0.65756667\n",
      "epoch 58 : loss 8.472816 ; accuracy 0.65991664\n",
      "epoch 59 : loss 8.386095 ; accuracy 0.66246665\n",
      "epoch 60 : loss 8.301958 ; accuracy 0.66465\n",
      "epoch 61 : loss 8.220263 ; accuracy 0.66713333\n",
      "epoch 62 : loss 8.140882 ; accuracy 0.6695333\n",
      "epoch 63 : loss 8.063702 ; accuracy 0.67165\n",
      "epoch 64 : loss 7.9886303 ; accuracy 0.6738\n",
      "epoch 65 : loss 7.9155707 ; accuracy 0.67593336\n",
      "epoch 66 : loss 7.844411 ; accuracy 0.67835\n",
      "epoch 67 : loss 7.775068 ; accuracy 0.6803667\n",
      "epoch 68 : loss 7.7074585 ; accuracy 0.68273336\n",
      "epoch 69 : loss 7.6415176 ; accuracy 0.68478334\n",
      "epoch 70 : loss 7.577179 ; accuracy 0.68663335\n",
      "epoch 71 : loss 7.5144167 ; accuracy 0.68836665\n",
      "epoch 72 : loss 7.45315 ; accuracy 0.6900333\n",
      "epoch 73 : loss 7.3933105 ; accuracy 0.6921667\n",
      "epoch 74 : loss 7.334822 ; accuracy 0.69386667\n",
      "epoch 75 : loss 7.277652 ; accuracy 0.6954\n",
      "epoch 76 : loss 7.2217293 ; accuracy 0.6968833\n",
      "epoch 77 : loss 7.1670055 ; accuracy 0.6983167\n",
      "epoch 78 : loss 7.113427 ; accuracy 0.69995\n",
      "epoch 79 : loss 7.060974 ; accuracy 0.7018\n",
      "epoch 80 : loss 7.0096164 ; accuracy 0.7032167\n",
      "epoch 81 : loss 6.959303 ; accuracy 0.7046\n",
      "epoch 82 : loss 6.9099865 ; accuracy 0.70608336\n",
      "epoch 83 : loss 6.8616323 ; accuracy 0.70765\n",
      "epoch 84 : loss 6.814228 ; accuracy 0.70895\n",
      "epoch 85 : loss 6.7677274 ; accuracy 0.71015\n",
      "epoch 86 : loss 6.7221165 ; accuracy 0.7114\n",
      "epoch 87 : loss 6.677355 ; accuracy 0.7124\n",
      "epoch 88 : loss 6.633417 ; accuracy 0.71383333\n",
      "epoch 89 : loss 6.590287 ; accuracy 0.71498334\n",
      "epoch 90 : loss 6.5479302 ; accuracy 0.7162\n",
      "epoch 91 : loss 6.5063176 ; accuracy 0.7172167\n",
      "epoch 92 : loss 6.4654207 ; accuracy 0.7183667\n",
      "epoch 93 : loss 6.425225 ; accuracy 0.71963334\n",
      "epoch 94 : loss 6.385713 ; accuracy 0.72076666\n",
      "epoch 95 : loss 6.3468738 ; accuracy 0.7218\n",
      "epoch 96 : loss 6.3086977 ; accuracy 0.7227\n",
      "epoch 97 : loss 6.271151 ; accuracy 0.72375\n",
      "epoch 98 : loss 6.23422 ; accuracy 0.72511667\n",
      "epoch 99 : loss 6.197889 ; accuracy 0.72641665\n",
      "epoch 100 : loss 6.1621494 ; accuracy 0.72728336\n",
      "epoch 101 : loss 6.1269813 ; accuracy 0.72828335\n",
      "epoch 102 : loss 6.0923676 ; accuracy 0.72928333\n",
      "epoch 103 : loss 6.0583067 ; accuracy 0.73025\n",
      "epoch 104 : loss 6.0247855 ; accuracy 0.7313333\n",
      "epoch 105 : loss 5.9918003 ; accuracy 0.7324333\n",
      "epoch 106 : loss 5.959349 ; accuracy 0.7335167\n",
      "epoch 107 : loss 5.9274125 ; accuracy 0.7344\n",
      "epoch 108 : loss 5.895984 ; accuracy 0.7353167\n",
      "epoch 109 : loss 5.8650494 ; accuracy 0.73611665\n",
      "epoch 110 : loss 5.8345776 ; accuracy 0.73715\n",
      "epoch 111 : loss 5.804542 ; accuracy 0.73803335\n",
      "epoch 112 : loss 5.7749457 ; accuracy 0.73895\n",
      "epoch 113 : loss 5.745778 ; accuracy 0.73976666\n",
      "epoch 114 : loss 5.717025 ; accuracy 0.74076664\n",
      "epoch 115 : loss 5.6886888 ; accuracy 0.7416833\n",
      "epoch 116 : loss 5.6607704 ; accuracy 0.7424667\n",
      "epoch 117 : loss 5.6332593 ; accuracy 0.74333334\n",
      "epoch 118 : loss 5.6061296 ; accuracy 0.7441\n",
      "epoch 119 : loss 5.5793777 ; accuracy 0.7449\n",
      "epoch 120 : loss 5.552993 ; accuracy 0.74585\n",
      "epoch 121 : loss 5.5269666 ; accuracy 0.74695\n",
      "epoch 122 : loss 5.5012703 ; accuracy 0.7477667\n",
      "epoch 123 : loss 5.4759135 ; accuracy 0.7485333\n",
      "epoch 124 : loss 5.4508824 ; accuracy 0.7492667\n",
      "epoch 125 : loss 5.426164 ; accuracy 0.7499833\n",
      "epoch 126 : loss 5.4017606 ; accuracy 0.7506833\n",
      "epoch 127 : loss 5.3776593 ; accuracy 0.7515\n",
      "epoch 128 : loss 5.353855 ; accuracy 0.75228333\n",
      "epoch 129 : loss 5.330333 ; accuracy 0.75301665\n",
      "epoch 130 : loss 5.3070874 ; accuracy 0.7536833\n",
      "epoch 131 : loss 5.2841134 ; accuracy 0.7543\n",
      "epoch 132 : loss 5.2614164 ; accuracy 0.7550833\n",
      "epoch 133 : loss 5.238978 ; accuracy 0.7556\n",
      "epoch 134 : loss 5.216801 ; accuracy 0.75615\n",
      "epoch 135 : loss 5.194883 ; accuracy 0.75685\n",
      "epoch 136 : loss 5.173229 ; accuracy 0.75736666\n",
      "epoch 137 : loss 5.1518254 ; accuracy 0.75813335\n",
      "epoch 138 : loss 5.1306677 ; accuracy 0.75885\n",
      "epoch 139 : loss 5.1097436 ; accuracy 0.75946665\n",
      "epoch 140 : loss 5.0890493 ; accuracy 0.7601167\n",
      "epoch 141 : loss 5.068596 ; accuracy 0.7607667\n",
      "epoch 142 : loss 5.048377 ; accuracy 0.76133335\n",
      "epoch 143 : loss 5.0283747 ; accuracy 0.7618333\n",
      "epoch 144 : loss 5.008594 ; accuracy 0.76233333\n",
      "epoch 145 : loss 4.9890175 ; accuracy 0.76283336\n",
      "epoch 146 : loss 4.9696436 ; accuracy 0.76341665\n",
      "epoch 147 : loss 4.9504704 ; accuracy 0.7640833\n",
      "epoch 148 : loss 4.931497 ; accuracy 0.76446664\n",
      "epoch 149 : loss 4.9127183 ; accuracy 0.7652\n",
      "epoch 150 : loss 4.8941255 ; accuracy 0.7657167\n",
      "epoch 151 : loss 4.875713 ; accuracy 0.7661833\n",
      "epoch 152 : loss 4.85748 ; accuracy 0.76671666\n",
      "epoch 153 : loss 4.8394313 ; accuracy 0.76713336\n",
      "epoch 154 : loss 4.8215656 ; accuracy 0.76775\n",
      "epoch 155 : loss 4.8038836 ; accuracy 0.7683\n",
      "epoch 156 : loss 4.7863736 ; accuracy 0.7687\n",
      "epoch 157 : loss 4.7690215 ; accuracy 0.76923335\n",
      "epoch 158 : loss 4.751831 ; accuracy 0.76986665\n",
      "epoch 159 : loss 4.734792 ; accuracy 0.7704\n",
      "epoch 160 : loss 4.7179165 ; accuracy 0.7708167\n",
      "epoch 161 : loss 4.701208 ; accuracy 0.77126664\n",
      "epoch 162 : loss 4.6846695 ; accuracy 0.77173334\n",
      "epoch 163 : loss 4.6682835 ; accuracy 0.77218336\n",
      "epoch 164 : loss 4.6520534 ; accuracy 0.7726\n",
      "epoch 165 : loss 4.635966 ; accuracy 0.7729833\n",
      "epoch 166 : loss 4.6200237 ; accuracy 0.77345\n",
      "epoch 167 : loss 4.604226 ; accuracy 0.77395\n",
      "epoch 168 : loss 4.588575 ; accuracy 0.77445\n",
      "epoch 169 : loss 4.573074 ; accuracy 0.77475\n",
      "epoch 170 : loss 4.5577145 ; accuracy 0.77531666\n",
      "epoch 171 : loss 4.542494 ; accuracy 0.77585\n",
      "epoch 172 : loss 4.5274115 ; accuracy 0.7761667\n",
      "epoch 173 : loss 4.5124664 ; accuracy 0.7766333\n",
      "epoch 174 : loss 4.4976525 ; accuracy 0.77701664\n",
      "epoch 175 : loss 4.482965 ; accuracy 0.77736664\n",
      "epoch 176 : loss 4.468399 ; accuracy 0.77788335\n",
      "epoch 177 : loss 4.4539523 ; accuracy 0.7783\n",
      "epoch 178 : loss 4.4396243 ; accuracy 0.7787833\n",
      "epoch 179 : loss 4.4254217 ; accuracy 0.7794333\n",
      "epoch 180 : loss 4.4113364 ; accuracy 0.77985\n",
      "epoch 181 : loss 4.3973684 ; accuracy 0.7803\n",
      "epoch 182 : loss 4.383517 ; accuracy 0.78063333\n",
      "epoch 183 : loss 4.3697743 ; accuracy 0.78095\n",
      "epoch 184 : loss 4.3561454 ; accuracy 0.7814\n",
      "epoch 185 : loss 4.342622 ; accuracy 0.78178334\n",
      "epoch 186 : loss 4.3292074 ; accuracy 0.7823333\n",
      "epoch 187 : loss 4.3158994 ; accuracy 0.78275\n",
      "epoch 188 : loss 4.302699 ; accuracy 0.78298336\n",
      "epoch 189 : loss 4.289604 ; accuracy 0.78333336\n",
      "epoch 190 : loss 4.2766123 ; accuracy 0.7837667\n",
      "epoch 191 : loss 4.2637153 ; accuracy 0.7841167\n",
      "epoch 192 : loss 4.2509255 ; accuracy 0.7845333\n",
      "epoch 193 : loss 4.2382426 ; accuracy 0.785\n",
      "epoch 194 : loss 4.2256637 ; accuracy 0.7854\n",
      "epoch 195 : loss 4.213174 ; accuracy 0.78583336\n",
      "epoch 196 : loss 4.2007785 ; accuracy 0.78606665\n",
      "epoch 197 : loss 4.1884723 ; accuracy 0.78653336\n",
      "epoch 198 : loss 4.1762557 ; accuracy 0.7867333\n",
      "epoch 199 : loss 4.164127 ; accuracy 0.78713334\n",
      "test loss 4.015631 ; accuracy 0.7939\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = mnist_dataset()\n",
    "\n",
    "\n",
    "for epoch in range(200):\n",
    "    loss, accuracy = train_one_step(model, optimizer, \n",
    "                                    tf.constant(train_data[0], dtype=tf.float32), \n",
    "                                    tf.constant(train_data[1], dtype=tf.int64))\n",
    "    print('epoch', epoch, ': loss', loss.numpy(), '; accuracy', accuracy.numpy())\n",
    "loss, accuracy = test(model, \n",
    "                      tf.constant(test_data[0], dtype=tf.float32), \n",
    "                      tf.constant(test_data[1], dtype=tf.int64))\n",
    "\n",
    "print('test loss', loss.numpy(), '; accuracy', accuracy.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
